#!/usr/bin/env python3
"""
Test du Syst√®me d'Agents AI - Sports Quest System
"""
import asyncio
import sys
import os

# Add the project root to the path so we can import our modules
sys.path.insert(0, os.path.abspath('..'))

from src.tools.database_tools import get_active_events, check_team_exists, get_team_community_size
from src.tools.quest_tools import generate_quest_content, calculate_quest_difficulty
from src.models.database import async_session
from src.models.event import SportsEvent
from src.models.team import Team
from src.models.quest import Quest
from sqlalchemy import select
from loguru import logger


async def test_database_tools():
    """Test 1: Database tools functionality"""
    print("1. üõ†Ô∏è  Testing database tools...")
    
    try:
        # Test get_active_events
        events = await get_active_events()
        print(f"   ‚úÖ Active events found: {len(events)}")
        
        if events:
            for event in events[:2]:  # Show first 2 events
                print(f"      - {event['title']} ({event['event_date']})")
        
        # Test check_team_exists
        team_check = await check_team_exists("PSG")
        print(f"   ‚úÖ Team existence check: PSG exists = {team_check.get('exists')}")
        
        # Test community size
        if team_check.get('exists'):
            community_size = await get_team_community_size(team_check['team_id'])
            print(f"   ‚úÖ Community size: {community_size} fans")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Database tools test failed: {e}")
        return False


async def test_quest_tools():
    """Test 2: Quest generation tools"""
    print("\n2. ‚ö° Testing quest generation tools...")
    
    try:
        # Test individual quest content generation
        individual_content = generate_quest_content(
            quest_type="individual",
            home_team="PSG",
            event_date="2025-07-15"
        )
        
        print(f"   ‚úÖ Individual quest generated:")
        print(f"      Title: {individual_content['title']}")
        print(f"      Target: {individual_content['target_metric']} ({individual_content['target_value']})")
        
        # Test clash quest content generation
        clash_content = generate_quest_content(
            quest_type="clash",
            home_team="PSG",
            away_team="Real Madrid",
            event_date="2025-07-15"
        )
        
        print(f"   ‚úÖ Clash quest generated:")
        print(f"      Title: {clash_content['title']}")
        print(f"      Target: {clash_content['target_metric']} ({clash_content['target_value']})")
        
        # Test difficulty calculation
        difficulty = calculate_quest_difficulty("individual", individual_content['target_value'])
        print(f"   ‚úÖ Difficulty calculated: {difficulty}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Quest tools test failed: {e}")
        return False


async def test_quest_creation_workflow():
    """Test 3: Full quest creation workflow"""
    print("\n3. üéØ Testing quest creation workflow...")
    
    try:
        async with async_session() as session:
            # Get first event
            stmt = select(SportsEvent).limit(1)
            result = await session.execute(stmt)
            event = result.scalar_one_or_none()
            
            if not event:
                print("   ‚ö†Ô∏è  No events found in database")
                return False
            
            print(f"   üé™ Testing with event: {event.title}")
            
            # Get teams involved
            home_team = await session.get(Team, event.home_team_id)
            away_team = await session.get(Team, event.away_team_id)
            
            print(f"   üë• Teams: {home_team.name} vs {away_team.name}")
            
            # Test team existence checks
            home_exists = await check_team_exists(home_team.name)
            away_exists = await check_team_exists(away_team.name)
            
            print(f"   ‚úÖ Home team exists: {home_exists.get('exists')}")
            print(f"   ‚úÖ Away team exists: {away_exists.get('exists')}")
            
            # Determine quest strategy
            if home_exists.get('exists') and away_exists.get('exists'):
                strategy = "both_teams"  # Individual + Clash quests
                print("   üéØ Strategy: Create individual quests + clash quest")
            elif home_exists.get('exists'):
                strategy = "home_only"
                print("   üéØ Strategy: Create home team quest only")
            elif away_exists.get('exists'):
                strategy = "away_only"
                print("   üéØ Strategy: Create away team quest only")
            else:
                strategy = "skip"
                print("   üéØ Strategy: Skip this event")
            
            # Test quest content generation based on strategy
            quests_generated = []
            
            if strategy in ["both_teams", "home_only"]:
                home_quest = generate_quest_content(
                    quest_type="individual",
                    home_team=home_team.name,
                    event_date=str(event.event_date)
                )
                quests_generated.append(f"Home Quest: {home_quest['title']}")
            
            if strategy in ["both_teams", "away_only"]:
                away_quest = generate_quest_content(
                    quest_type="individual",
                    home_team=away_team.name,
                    event_date=str(event.event_date)
                )
                quests_generated.append(f"Away Quest: {away_quest['title']}")
            
            if strategy == "both_teams":
                clash_quest = generate_quest_content(
                    quest_type="clash",
                    home_team=home_team.name,
                    away_team=away_team.name,
                    event_date=str(event.event_date)
                )
                quests_generated.append(f"Clash Quest: {clash_quest['title']}")
            
            print(f"   ‚úÖ Generated {len(quests_generated)} quest(s):")
            for quest in quests_generated:
                print(f"      - {quest}")
            
            return len(quests_generated) > 0
        
    except Exception as e:
        print(f"   ‚ùå Quest creation workflow test failed: {e}")
        return False


async def test_preference_analysis():
    """Test 4: User preference analysis simulation"""
    print("\n4. üë§ Testing preference analysis...")
    
    try:
        # Simulate user preferences
        test_users = [
            {
                "user_id": 1,
                "teams": ["PSG"],
                "language": "fr",
                "engagement_level": "high"
            },
            {
                "user_id": 2,
                "teams": ["Real Madrid"],
                "language": "es",
                "engagement_level": "medium"
            },
            {
                "user_id": 3,
                "teams": ["PSG", "Barcelona"],
                "language": "en",
                "engagement_level": "high"
            }
        ]
        
        print(f"   ‚úÖ Testing with {len(test_users)} users")
        
        # Test preference-based quest customization
        for user in test_users:
            print(f"   üë§ User {user['user_id']} ({user['language']}):")
            
            for team in user['teams']:
                # Check if team exists
                team_check = await check_team_exists(team)
                
                if team_check.get('exists'):
                    # Generate personalized quest
                    quest_content = generate_quest_content(
                        quest_type="individual",
                        home_team=team,
                        event_date="2025-07-15",
                        user_preferences={
                            "language": user['language'],
                            "engagement_level": user['engagement_level']
                        }
                    )
                    
                    print(f"      - {team}: {quest_content['title'][:50]}...")
                else:
                    print(f"      - {team}: Team not found in system")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Preference analysis test failed: {e}")
        return False


async def test_quest_validation():
    """Test 5: Quest validation process"""
    print("\n5. ‚úÖ Testing quest validation...")
    
    try:
        # Generate test quest content
        test_quest = generate_quest_content(
            quest_type="individual",
            home_team="PSG",
            event_date="2025-07-15"
        )
        
        print(f"   üìù Testing quest: {test_quest['title']}")
        
        # Validation tests
        validations = []
        
        # Content validation
        content_valid = len(test_quest['title']) > 10 and len(test_quest['description']) > 20
        validations.append(("Content length", content_valid))
        
        # Target validation
        target_valid = test_quest['target_value'] > 0 and test_quest['target_metric'] is not None
        validations.append(("Target metrics", target_valid))
        
        # Hashtag validation
        hashtag_valid = len(test_quest.get('hashtags', [])) >= 2
        validations.append(("Hashtags", hashtag_valid))
        
        # Content suggestions validation
        suggestions_valid = len(test_quest.get('content_suggestions', [])) >= 1
        validations.append(("Content suggestions", suggestions_valid))
        
        # Display validation results
        for validation_name, is_valid in validations:
            status = "‚úÖ" if is_valid else "‚ùå"
            print(f"   {status} {validation_name}: {'Valid' if is_valid else 'Invalid'}")
        
        # Overall validation score
        valid_count = sum(1 for _, valid in validations if valid)
        validation_score = valid_count / len(validations) * 100
        
        print(f"   üìä Validation score: {validation_score:.1f}% ({valid_count}/{len(validations)})")
        
        return validation_score >= 80  # 80% validation threshold
        
    except Exception as e:
        print(f"   ‚ùå Quest validation test failed: {e}")
        return False


async def test_distribution_simulation():
    """Test 6: Quest distribution simulation"""
    print("\n6. üì° Testing quest distribution simulation...")
    
    try:
        # Simulate distribution to different user segments
        distribution_targets = [
            {"segment": "PSG Hardcore Fans", "count": 150, "channel": "push_notification"},
            {"segment": "PSG Casual Fans", "count": 300, "channel": "in_app"},
            {"segment": "General Football Fans", "count": 50, "channel": "social_media"},
        ]
        
        total_distributed = 0
        
        for target in distribution_targets:
            # Simulate distribution
            distributed = target['count']
            total_distributed += distributed
            
            print(f"   üì§ {target['segment']}: {distributed} users via {target['channel']}")
        
        print(f"   ‚úÖ Total distributed: {total_distributed} users")
        
        # Simulate engagement metrics
        estimated_engagement = total_distributed * 0.25  # 25% engagement rate
        print(f"   üìà Estimated engagement: {estimated_engagement:.0f} users")
        
        return total_distributed > 0
        
    except Exception as e:
        print(f"   ‚ùå Distribution simulation test failed: {e}")
        return False


async def test_full_agent_workflow():
    """Test 7: Complete agent workflow simulation"""
    print("\n7. ü§ñ Testing complete agent workflow...")
    
    try:
        print("   üé¨ Simulating: New Event Trigger -> Quest Generation -> Distribution")
        
        # Step 1: Event detection
        events = await get_active_events()
        if not events:
            print("   ‚ö†Ô∏è  No active events to process")
            return False
        
        event = events[0]
        print(f"   üé™ Processing event: {event['title']}")
        
        # Step 2: Team analysis
        teams = event['title'].split(' vs ')
        if len(teams) != 2:
            teams = [event['title'], "Unknown"]
        
        home_team, away_team = teams[0].strip(), teams[1].strip()
        
        # Step 3: Quest strategy determination
        home_exists = await check_team_exists(home_team)
        away_exists = await check_team_exists(away_team)
        
        quest_count = 0
        
        # Step 4: Quest generation
        if home_exists.get('exists'):
            home_quest = generate_quest_content("individual", home_team, str(event['event_date']))
            quest_count += 1
            print(f"   ‚ö° Generated home quest: {home_quest['title'][:40]}...")
        
        if away_exists.get('exists'):
            away_quest = generate_quest_content("individual", away_team, str(event['event_date']))
            quest_count += 1
            print(f"   ‚ö° Generated away quest: {away_quest['title'][:40]}...")
        
        if home_exists.get('exists') and away_exists.get('exists'):
            clash_quest = generate_quest_content("clash", home_team, away_team, str(event['event_date']))
            quest_count += 1
            print(f"   ‚ö° Generated clash quest: {clash_quest['title'][:40]}...")
        
        # Step 5: Validation
        validation_passed = quest_count > 0
        print(f"   ‚úÖ Validation: {'Passed' if validation_passed else 'Failed'}")
        
        # Step 6: Distribution simulation
        if validation_passed:
            estimated_users = quest_count * 200  # 200 users per quest
            print(f"   üì° Distribution: {estimated_users} users targeted")
        
        print(f"   üéØ Workflow result: {quest_count} quest(s) generated and distributed")
        
        return quest_count > 0
        
    except Exception as e:
        print(f"   ‚ùå Full agent workflow test failed: {e}")
        return False


async def main():
    """Run all agent system tests"""
    print("ü§ñ Testing Sports Quest AI Agent System")
    print("=" * 70)
    
    tests = [
        ("Database Tools", test_database_tools),
        ("Quest Tools", test_quest_tools),
        ("Quest Creation Workflow", test_quest_creation_workflow),
        ("Preference Analysis", test_preference_analysis),
        ("Quest Validation", test_quest_validation),
        ("Distribution Simulation", test_distribution_simulation),
        ("Full Agent Workflow", test_full_agent_workflow)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            success = await test_func()
            if success:
                passed += 1
        except Exception as e:
            print(f"   ‚ùå Test '{test_name}' crashed: {e}")
    
    # Final summary
    print(f"\nü§ñ AGENT SYSTEM TEST RESULTS:")
    print(f"   Tests passed: {passed}/{total}")
    print(f"   Success rate: {passed/total*100:.1f}%")
    
    if passed == total:
        print(f"\nüéâ ALL AGENT TESTS PASSED!")
        print(f"‚úÖ Database tools operational")
        print(f"‚úÖ Quest generation working")
        print(f"‚úÖ Workflow logic validated")
        print(f"‚úÖ Preference analysis functional")
        print(f"‚úÖ Validation system working")
        print(f"‚úÖ Distribution simulation ready")
        print(f"‚úÖ Full agent workflow operational")
        print(f"\nüöÄ Agent system ready for production!")
    elif passed >= total * 0.7:  # 70% or more
        print(f"\n‚úÖ AGENT SYSTEM MOSTLY WORKING! {passed}/{total} tests passed")
        print(f"‚ö†Ô∏è  Some components may need fine-tuning")
        print(f"‚úÖ Core agent functionality is operational")
    else:
        print(f"\n‚ö†Ô∏è  AGENT SYSTEM NEEDS WORK! Only {passed}/{total} tests passed")
        print(f"‚ùå Significant issues detected in agent workflow")
        print(f"üîß Check logs for specific problems")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    asyncio.run(main())